{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "http://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle gives us mnist train/test data in csv files. First column of train is the label and the other 784 columns are the pixel values of the 28x28x1 images. We use pandas to load the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the train and test data.\n",
    "train_data = pd.read_csv('../mnist_data/train.csv')\n",
    "test_data = pd.read_csv('../mnist_data/test.csv')\n",
    "#train_data.head(3)  # Sanity check display the first 3 elements of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate the labels from the input data.\n",
    "train_y = train_data.values[:,0]\n",
    "train_x = train_data.values[:,1:].astype(np.float32)\n",
    "test_x = test_data.values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate how much of our training data is for train and validation.\n",
    "VALIDATION_PERCENT = 0.1  # 0.0 to 1.0\n",
    "num_train = len(train_y)\n",
    "num_val = int(num_train*VALIDATION_PERCENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data back to images, transpose to N,C,H,W format for pytorch. \n",
    "\n",
    "train_x = train_x.reshape([-1, 28, 28, 1]).transpose((0,3,1,2))\n",
    "test_x = test_x.reshape([-1, 28, 28, 1]).transpose((0,3,1,2))\n",
    "\n",
    "# Split for train/val.\n",
    "val_x = train_x[0:num_val]\n",
    "val_y = train_y[0:num_val]\n",
    "train_x = train_x[num_val:]\n",
    "train_y = train_y[num_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check to see an example and print its label.\n",
    "example_im = train_x[0,0,:,:]\n",
    "plt.imshow(example_im, cmap='gray')\n",
    "plt.show()\n",
    "train_y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a pytorch dataset wrapper by creating a class that inherits from Dataset. Will be used to store our datasets so we can use the pytorch DataLoader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, x, y=None):\n",
    "        self.data = x\n",
    "        self.labels = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.labels is not None:\n",
    "            return self.data[idx], self.labels[idx]\n",
    "        else:\n",
    "            return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MnistDataset(train_x, train_y)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=200, shuffle=True)\n",
    "\n",
    "val_dataset = MnistDataset(val_x, val_y)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=200, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define our CNN model for classifying our digits data. Define it as a class inheriting from nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MnistCNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
    "        self.max2x2 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels= 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.fc1 = nn.Linear(in_features=7*7*32, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=84)\n",
    "        self.out = nn.Linear(in_features=84, out_features=10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        act1 = self.relu(self.conv1(x))\n",
    "        act2 = self.max2x2(act1)\n",
    "        act3 = self.relu(self.conv2(act2))\n",
    "        act4 = self.max2x2(act3)\n",
    "        flatten = act4.view(-1, 7*7*32)\n",
    "        act5 = self.relu(self.fc1(flatten))\n",
    "        act6 = self.relu(self.fc2(act5))\n",
    "        out = self.out(act6)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, loss_func, optimizer, epochs=10):\n",
    "    \n",
    "    # Switch to train mode (for things like Batch norm and dropout).\n",
    "    model.train()\n",
    "    \n",
    "    loss_history = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i_batch, (x_batch, y_batch) in enumerate(dataloader):            \n",
    "            # Compute output and loss.\n",
    "            output = model(x_batch)\n",
    "            loss = loss_func(output, y_batch)\n",
    "        \n",
    "            # Zero our gradients/backprop and perform and SGD step.\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print(loss)           \n",
    "        loss_history.append(loss)\n",
    "        \n",
    "    return loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer and loss function.\n",
    "model = MnistCNN()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train our model.\n",
    "train_model(model, train_dataloader, loss_func, optimizer, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model(model, dataloader):\n",
    "    model.eval()\n",
    "    num_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for i_batch, (x_batch, y_batch) in enumerate(dataloader):                \n",
    "            output = model(x_batch)\n",
    "\n",
    "            _, output = torch.max(output, dim=1)\n",
    "        \n",
    "            num_correct += torch.sum(output == y_batch)\n",
    "\n",
    "    return num_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_correct = test_model(model, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.986904761904762\n"
     ]
    }
   ],
   "source": [
    "if VALIDATION_PERCENT > 0:\n",
    "    accuracy = float(num_correct)/ len(val_dataset)\n",
    "    print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run our test set through to predict labels then save to csv for kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_x = torch.from_numpy(test_x)\n",
    "test_labels = []\n",
    "for i in range(len(test_x)):\n",
    "    \n",
    "    test_batch = test_x[i].unsqueeze_(0)\n",
    "    \n",
    "    output = model(test_batch)\n",
    "    _, output = torch.max(output, dim=1)\n",
    "    \n",
    "    test_labels.append(int(output.data.numpy()))\n",
    "\n",
    "np.savetxt(\"foo.csv\", test_labels, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
