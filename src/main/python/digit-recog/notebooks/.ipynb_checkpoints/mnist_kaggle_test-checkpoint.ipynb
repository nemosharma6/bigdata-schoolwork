{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "http://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dateutil 2.5.0 is the minimum required version",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-87a879a5e362>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# numpy compat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/compat/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mLooseVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdateutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mLooseVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'2.5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dateutil 2.5.0 is the minimum required version'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdateutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparser\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_date_parser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0mparse_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_date_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: dateutil 2.5.0 is the minimum required version"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle gives us mnist train/test data in csv files. First column of train is the label and the other 784 columns are the pixel values of the 28x28x1 images. We use pandas to load the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3e965ba23eb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Read in the train and test data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../mnist_pytorch/train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../mnist_pytorch/test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#train_data.head(3)  # Sanity check display the first 3 elements of training.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Read in the train and test data.\n",
    "train_data = pd.read_csv('../mnist_pytorch/train.csv')\n",
    "test_data = pd.read_csv('../mnist_pytorch/test.csv')\n",
    "#train_data.head(3)  # Sanity check display the first 3 elements of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Seperate the labels from the input data.\n",
    "train_y = train_data.values[:,0]\n",
    "train_x = train_data.values[:,1:].astype(np.float32)\n",
    "test_x = test_data.values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate how much of our training data is for train and validation.\n",
    "VALIDATION_PERCENT = 0.1  # 0.0 to 1.0\n",
    "num_train = len(train_y)\n",
    "num_val = int(num_train*VALIDATION_PERCENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reshape data back to images, transpose to N,C,H,W format for pytorch. \n",
    "\n",
    "train_x = train_x.reshape([-1, 28, 28, 1]).transpose((0,3,1,2))\n",
    "test_x = test_x.reshape([-1, 28, 28, 1]).transpose((0,3,1,2))\n",
    "\n",
    "# Split for train/val.\n",
    "val_x = train_x[0:num_val]\n",
    "val_y = train_y[0:num_val]\n",
    "train_x = train_x[num_val:]\n",
    "train_y = train_y[num_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+KWiDL9UlOGXivp/6dA7HQVHlpsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14d4e2d97b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check to see an example and print its label.\n",
    "example_im = train_x[0,0,:,:]\n",
    "plt.imshow(example_im, cmap='gray')\n",
    "plt.show()\n",
    "train_y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a pytorch dataset wrapper by creating a class that inherits from Dataset. Will be used to store our datasets so we can use the pytorch DataLoader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MnistDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, x, y=None):\n",
    "        self.data = x\n",
    "        self.labels = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.labels is not None:\n",
    "            return self.data[idx], self.labels[idx]\n",
    "        else:\n",
    "            return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset = MnistDataset(train_x, train_y)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=200, shuffle=True)\n",
    "\n",
    "val_dataset = MnistDataset(val_x, val_y)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=200, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define our CNN model for classifying our digits data. Define it as a class inheriting from nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MnistCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MnistCNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
    "        self.max2x2 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels= 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.fc1 = nn.Linear(in_features=7*7*32, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=84)\n",
    "        self.out = nn.Linear(in_features=84, out_features=10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        act1 = self.relu(self.conv1(x))\n",
    "        act2 = self.max2x2(act1)\n",
    "        act3 = self.relu(self.conv2(act2))\n",
    "        act4 = self.max2x2(act3)\n",
    "        flatten = act4.view(-1, 7*7*32)\n",
    "        act5 = self.relu(self.fc1(flatten))\n",
    "        act6 = self.relu(self.fc2(act5))\n",
    "        out = self.out(act6)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, loss_func, optimizer, epochs=10):\n",
    "    \n",
    "    # Switch to train mode (for things like Batch norm and dropout).\n",
    "    model.train()\n",
    "    \n",
    "    loss_history = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i_batch, (x_batch, y_batch) in enumerate(dataloader):            \n",
    "            # Compute output and loss.\n",
    "            output = model(x_batch)\n",
    "            loss = loss_func(output, y_batch)\n",
    "        \n",
    "            # Zero our gradients/backprop and perform and SGD step.\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print(loss)           \n",
    "        loss_history.append(loss)\n",
    "        \n",
    "    return loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define optimizer and loss function.\n",
    "model = MnistCNN()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0728, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0282, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0355, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0319, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0344, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0403, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0211, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0076, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0333, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0120, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor(0.0728, grad_fn=<NllLossBackward>),\n",
       " tensor(0.0282, grad_fn=<NllLossBackward>),\n",
       " tensor(0.0355, grad_fn=<NllLossBackward>),\n",
       " tensor(0.0319, grad_fn=<NllLossBackward>),\n",
       " tensor(0.0344, grad_fn=<NllLossBackward>),\n",
       " tensor(0.0403, grad_fn=<NllLossBackward>),\n",
       " tensor(0.0211, grad_fn=<NllLossBackward>),\n",
       " tensor(0.0076, grad_fn=<NllLossBackward>),\n",
       " tensor(0.0333, grad_fn=<NllLossBackward>),\n",
       " tensor(0.0120, grad_fn=<NllLossBackward>)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train our model.\n",
    "train_model(model, train_dataloader, loss_func, optimizer, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model(model, dataloader):\n",
    "    model.eval()\n",
    "    num_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for i_batch, (x_batch, y_batch) in enumerate(dataloader):                \n",
    "            output = model(x_batch)\n",
    "\n",
    "            _, output = torch.max(output, dim=1)\n",
    "        \n",
    "            num_correct += torch.sum(output == y_batch)\n",
    "\n",
    "    return num_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_correct = test_model(model, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.986904761904762\n"
     ]
    }
   ],
   "source": [
    "if VALIDATION_PERCENT > 0:\n",
    "    accuracy = float(num_correct)/ len(val_dataset)\n",
    "    print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run our test set through to predict labels then save to csv for kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_x = torch.from_numpy(test_x)\n",
    "test_labels = []\n",
    "for i in range(len(test_x)):\n",
    "    \n",
    "    test_batch = test_x[i].unsqueeze_(0)\n",
    "    \n",
    "    output = model(test_batch)\n",
    "    _, output = torch.max(output, dim=1)\n",
    "    \n",
    "    test_labels.append(int(output.data.numpy()))\n",
    "\n",
    "np.savetxt(\"foo.csv\", test_labels, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
